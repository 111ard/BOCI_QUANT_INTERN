#### 0. summary与report的区别；backtest，analysis，summary（report）合并
```
--options ["backtest", "analysis", "report"]
```

#### 1. 把class以外的都装入class

#### 2. method加入第三种，backtest_only；method与analysis，

#### 3. 遇到新的功能，优先“找”而非“造”

```
parser.add_argument(…, choices={"0", "1", ...})
```

#### 4. logger目录不存在，创建 —— 任何涉及到目录的都是这样处理

#### 5. logger print screen

#### 6. 所有目前是写死的常量，放到config里，如：temp_dir的路径，logfile的名字（带时间戳，区分每一次输出），stock_pool.xlsx， omitted.txt等等，程序里不出现

#### 7. 所有涉及到路径的，不能用+连接

#### 8. 把程序的流程log清楚，每一步在干嘛，什么结果，详细显示

#### 9. 精确catch每一个exception，打印出原始的exception，并把自己的信息加入输出

#### 10. output_Func.py改名

#### 11. 加入lib.py，把通用性工具性代码放入，比如logging的产生；其他脚本都可以import lib，从而拿到logger

## 12. 不要从单个功能的角度思考，面向单个功能写代码，把逻辑抽象出来，从整体出发

## 13. 尽量的模块化，重复使用的功能做成一个function，代码的复用

```
    main():
        if option.backtest:
            if category == selected_factors (原selected_factor):
                all_factors = args.selected_factors
                self.run_basic_mode(all_factors)
                
            if category == selected_folders (原selected_files):
                # 扫描文件夹，找到所有的因子名，回到第一种模式
                all_folders = args.selected_folders
                all_factors = []
                for folder in all_folders:
                    all_factors += self.find_factors_in_folder(folder)
                    self.run_basic_mode(all_factors)
                    
            if category == all:
                # 扫描factor文件夹，得到所有的文件夹，再回到第二种模式
                all_folders = self.scan_factor_folder()
                all_factors = []
                for folder in all_folders:
                    all_factors += self.find_factors_in_folder(folder)
                    self.run_basic_mode(all_factors)
        
        if option.analysis:
            run_analysis(all_factors)
        if report or backtest_and_report:
            run_report(all_factors)
            
    # ===================================
    # 最基础的单元是处理每个因子，抓住这个本质
    def run_basic_mode(all_factors):
        # 单个模式
        for factor_name in all_factors:
            self.process_factor(factor)
        
        # !!! 在此处改成multiprocess !!!
        with Pool(processes=4) as pool:
            pool.map(process_factor, all_factors)
            
    # 多进程跑这个函数即可
    def process_factor(factor_name):
        # 1. 检查factor相关文件是否存在
        if not self.factor_exists(factor_name):
            print("Factor File not exists")
            return
        if not self.factor_csv_exists(factor_name):
            print("Factor output csv file not exists")
            return
            
        # 2. 检查factor的输出csv
        factor_df = check_factor_csv(factor_name)
        
        # 3. 根据factor_df的返回值处理
        if factor_df is None:
            print("Factor是最新状态")
        else:
            print("Factor需要更新")
            run_factor(factor_name, factor_df)
    
    def check_factor_csv(factor_name):
        if factor_csv not exist:
            # 说明没跑过
            return pd.DataFrame()
        else:
            factor_df = self.load_factor(factor_name)
        # 检查是否完整，检查index与config日期
        completed = self.check_factor_completion()
        if completed:
            return None
        else:
            return factor_df
            
    def run_factor(factor_name, factor_df):
        # 跑因子值，存成文件
        if len(factor_df) == 0:
            # 说明没跑过，全量跑
            print(factor_name, 全量跑)
            # actural work
        else:
            new_start = factor_df.index - 1
            print(factor_name, 增量跑，new_start date is: xxxx)
            # 跑增量
            # 与factor_df合并（注意少取一天的合并）
        # 输出csv文件
```